{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection -> Face Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 카메라 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera # 카메라 관련 라이브러리\n",
    "from jetbot import bgr8_to_jpeg # widget통해서 이미지 전송시 bgr type을 jpeg로 변환\n",
    "\n",
    "camera = Camera.instance(width=720, height=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오류 뜨거나 (initialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 왼쪽 정지버튼 아이콘 -> 전체 커널 ShutDown\n",
    "# 2) 내 JupyterLab에서 Kernel Restart (단축키 : 0, 0)\n",
    "# 3) 카메라 인스턴스 생성!!\n",
    "\n",
    "# 이래도 에러 -> 재부팅\n",
    "# 그래도 에러 -> 카메라 접촉 불량"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 카메라 프리뷰 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf841b9b3f14863b2c11e5ad0c20447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='300', width='300')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 텍스트 상자, 슬라이드, 체크박스, 드롭다운, 버튼 등 시각화관련 위젯\n",
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "# 원격으로 접속했을 때, 카메라 정보 받아오는 라이브러리\n",
    "from IPython.display import display\n",
    "\n",
    "detect_face = widgets.Image(width=300, height=300, format='jpeg')\n",
    "display(detect_face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Face Detect (얼굴 감지)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HaarCascade "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습된 모델을 가져오자!!\n",
    "- https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "- 전체 파일 및 디렉터리를 가져올 필요는 없다\n",
    "- git clone 대신에 curl 사용\n",
    "\n",
    "- curl : url 통해서 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  908k  100  908k    0     0   927k      0 --:--:-- --:--:-- --:--:-- 1963k\n"
     ]
    }
   ],
   "source": [
    "# curl 명령어\n",
    "# -L : Redirect 따라가서 가져오기\n",
    "# -O : 형식 그대로 가져오기\n",
    "!curl -L -O https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "face_x = face_y = face_w = face_h = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI 활용, 눈 검출!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  333k  100  333k    0     0   539k      0 --:--:-- --:--:-- --:--:--  839k\n"
     ]
    }
   ],
   "source": [
    "### 눈 관련 학습 모델 다운로드!!\n",
    "!curl -L -O https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_eye.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 눈 관련 cascade 모델 생성!!\n",
    "# 눈 좌표도 초기화!!\n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "eye_x = eye_y = eye_w = eye_h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IT 직군은 무엇이 있을까?\n",
    "# Data Science -> Modeling, Engineering\n",
    "# Model : 직접 ML, DL 모델 설계\n",
    "# Engineering : 내 서비스에 어떤 모델을 써야 될까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-962a2350a124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 학습된 데이터가 300 x 300 이므로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while 1:\n",
    "    frame = camera.value\n",
    "    frame = cv2.resize(frame, (300, 300)) # 학습된 데이터가 300 x 300 이므로\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray) # 이미지 내에서 얼굴 검출!!\n",
    "    \n",
    "    # 만약, 검출되었다면\n",
    "    if len(faces) > 0:\n",
    "        (face_x, face_y, face_w, face_h) = faces[0]\n",
    "    \n",
    "        # 사각형 그리자 rectangle(img, start, end, bgrcolor, thickness)\n",
    "        cv2.rectangle(frame, (face_x, face_y), (face_x + face_w, face_y + face_h), (0, 255, 0), 4)\n",
    "        \n",
    "        roi_region = gray[face_y : face_y + face_h, face_x : face_x + face_w]\n",
    "        roi_color = frame[face_y : face_y + face_h, face_x : face_x + face_w]\n",
    "        \n",
    "        eyes = eye_cascade.detectMultiScale(roi_region)\n",
    "        \n",
    "        # 눈이 검출되었다면 (눈은 2개임...)\n",
    "        for eye_x, eye_y, eye_w, eye_h in eyes:\n",
    "            cv2.rectangle(roi_color, (eye_x, eye_y), (eye_x + eye_w, eye_y + eye_h), (255, 0, 0), 2)\n",
    "    \n",
    "    detect_face.value = bgr8_to_jpeg(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 추적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ServoMotor 관련된 port 권한 부여\n",
    "- sudo chmod 777 /dev/ttyTHS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serial Open!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Carrier board is not from a Jetson Developer Kit.\n",
      "WARNNIG: Jetson.GPIO library has not been verified with this carrier board,\n",
      "WARNING: and in fact is unlikely to work correctly.\n"
     ]
    }
   ],
   "source": [
    "# ServoMotor 제어\n",
    "from servoserial import ServoSerial\n",
    "\n",
    "servo = ServoSerial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x08\\x98\\x00\\n\\x02\\n\\x8c\\x00\\n\\xf5'\n"
     ]
    }
   ],
   "source": [
    "servo.Servo_serial_double_control(1, 2200, 2, 2700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_x = 2200\n",
    "center_y = 2700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. PID(비례-적분-미분)\n",
    "- 카메라가 얼굴 탐지 영역의 중심점을 찾아가는 데 \n",
    "- 어느정도로 움직여야 하는지 그 정도를 계산하는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PID\n",
    "\n",
    "xservo_pid = PID.PositionalPID(1.9, 0.3, 0.35)\n",
    "yservo_pid = PID.PositionalPID(1.5, 0.2, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while 1:\n",
    "    frame = camera.value\n",
    "    frame = cv2.resize(frame, (300, 300)) # 학습된 데이터가 300 x 300 이므로\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray) # 이미지 내에서 얼굴 검출!!\n",
    "    \n",
    "    # 만약, 검출되었다면\n",
    "    if len(faces) > 0:\n",
    "        (face_x, face_y, face_w, face_h) = faces[0]\n",
    "    \n",
    "        # 사각형 그리자 rectangle(img, start, end, bgrcolor, thickness)\n",
    "        cv2.rectangle(frame, (face_x, face_y), (face_x + face_w, face_y + face_h), (0, 255, 0), 4)\n",
    "        \n",
    "        # PID 활용해서 카메라 서보모터가 얼굴을 따라가자!!\n",
    "        \n",
    "        # X 오프셋\n",
    "        xservo_pid.SystemOutput = face_x + face_w / 2  # x축 중심점\n",
    "        xservo_pid.SetStepSignal(150)\n",
    "        xservo_pid.SetInertiaTime(0.01, 0.006) # 다음 반응까지의 시간\n",
    "        \n",
    "        target_x = int(center_x + xservo_pid.SystemOutput)\n",
    "        \n",
    "        # Y 오프셋\n",
    "        yservo_pid.SystemOutput = face_y + face_h / 2  # y축 중심점\n",
    "        yservo_pid.SetStepSignal(150)\n",
    "        yservo_pid.SetInertiaTime(0.01, 0.006)\n",
    "        \n",
    "        target_y = int(center_y + yservo_pid.SystemOutput)\n",
    "        \n",
    "        servo.Servo_serial_double_control(1, target_x, 2, target_y)\n",
    "        \n",
    "        \n",
    "        roi_region = gray[face_y : face_y + face_h, face_x : face_x + face_w]\n",
    "        roi_color = frame[face_y : face_y + face_h, face_x : face_x + face_w]\n",
    "        \n",
    "        eyes = eye_cascade.detectMultiScale(roi_region)\n",
    "        \n",
    "        # 눈이 검출되었다면 (눈은 2개임...)\n",
    "        for eye_x, eye_y, eye_w, eye_h in eyes:\n",
    "            cv2.rectangle(roi_color, (eye_x, eye_y), (eye_x + eye_w, eye_y + eye_h), (255, 0, 0), 2)\n",
    "    \n",
    "    detect_face.value = bgr8_to_jpeg(frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
