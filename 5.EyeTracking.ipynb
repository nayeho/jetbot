{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region Of Interest\n",
    "# 얼굴과 눈 인식하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera\n",
    "from jetbot import bgr8_to_jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera.instance(width=720, height=720) # 영상을 받아들일 카메라 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카메라 영상의 프레임 이미지를 얻은 다음, 그 이미지 속에서 검출할 객체 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serial Open!\n",
      "245\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x08\\x98\\x00\\n\\x02\\n\\x8c\\x00\\n\\xf5'\n"
     ]
    }
   ],
   "source": [
    "# 카메라 방향 제어를 위한 Pan/Tilt Servo 인스턴스 생성\n",
    "from servoserial import ServoSerial\n",
    "import time\n",
    "\n",
    "pantilt = ServoSerial() \n",
    "\n",
    "# 초기 카메라 방향을 좌우, 상하 중간을 바라보도록 설정\n",
    "pantilt.Servo_serial_double_control(1, 2200, 2, 2700)\n",
    "time.sleep(0.5) # 코드 합칠 떄를 대비 동작 시간 대기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검출 영역 좌표와 크기\n",
    "\n",
    "global face_x, face_y, face_w, face_h\n",
    "\n",
    "face_x = face_y = face_w = face_h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796682d9540e4312af2ae5347898fa79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='300', width='300')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#카메라 프리뷰 위젯 만들기\n",
    "\n",
    "import traitlets # 위젯의 속성등을 다루는 라이브러리\n",
    "import ipywidgets.widgets as widgets # 텍스트 상자, 버튼, 슬라이더, 체크 박스, 드롭다운 메뉴 등 시각화 다루기\n",
    "from IPython.display import display\n",
    "\n",
    "face_image = widgets.Image(format='jpeg', width=300, height=300)\n",
    "display(face_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for jetbot: \n"
     ]
    }
   ],
   "source": [
    "!sudo apt install curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curl 설치 후 xml 다운\n",
    "# -L : 리디렉션 응답 시 처리\n",
    "# -O : 저장할 파일명으로 리소스 파일명 그대로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  908k  100  908k    0     0   974k      0 --:--:-- --:--:-- --:--:--  974k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -O https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  333k  100  333k    0     0   484k      0 --:--:-- --:--:-- --:--:-- 9089k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -O https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_eye.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  767k  100  767k    0     0  1011k      0 --:--:-- --:--:-- --:--:-- 1011k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -O https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_upperbody.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAAR Cascade Classifier 학습 데이터 로딩하기\n",
    "\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') # 정면 얼굴 검출용\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml') # 눈 검출용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7e2469943334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 흑백 이미지로 변환하여 검출에 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 이미지 내에서 신체 검출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#검출된 내용이 있으면\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while 1:\n",
    "    frame = camera.value\n",
    "    frame = cv2.resize(frame, (300, 300)) # 이미지를 학습 데이터와 동일한 크기로 변환\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # 흑백 이미지로 변환하여 검출에 사용\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray) # 이미지 내에서 신체 검출\n",
    "    \n",
    "    if len(faces) > 0: #검출된 내용이 있으면\n",
    "        (face_x, face_y, face_w, face_h) = faces[0]\n",
    "        \n",
    "        # 검출 영역 사각 박스로 표시\n",
    "        cv2.rectangle(frame, (face_x, face_y), (face_x + face_h, face_y + face_w), (0, 255, 0), 4)\n",
    "        \n",
    "        # 눈 검출은 얼굴이 검출된 영역 내부에서만 진행하기 위해 ROI 생성\n",
    "        roi_gray = gray[face_y : face_y + face_h, face_x : face_x + face_w]\n",
    "        roi_color = frame[face_y : face_y + face_h, face_x : face_x + face_w]\n",
    "        \n",
    "        # 얼굴 안에서 눈을 검출\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        \n",
    "        # 눈이 검출되었다면 눈 위치에 대한 좌표 정보 리턴\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            \n",
    "            # 원본 이미지에 눈의 위치를 표시 (roi_color에 표시하면 원본 이미지에도 표시됨)\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (255, 0, 0), 2)\n",
    "        \n",
    "    #결과 이미지를 프리뷰 위젯에 표시\n",
    "    face_image.value = bgr8_to_jpeg(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
